<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Oumar&#39;s Website">
    
    <link rel="shortcut icon" href="http://oumarkaba.github.io/favicon.ico">
    
    <link rel="stylesheet" href="/css/style.min.css">

    <title>Publications</title>
</head>
<body><header id="banner">
    <h2><a href="http://oumarkaba.github.io">Sékou-Oumar Kaba</a></h2>
    <nav>
        <ul>
            <li>
                <a href="/resume/" title="resume">resume</a>
            </li><li>
                <a href="/publications/" title="publications">publications</a>
            </li>
        </ul>
    </nav>
</header>
<main id="content">
<article>
    <header id="post-header">
        <h1>Publications</h1>
        <div></div>
    </header><!-- ### Papers -->
<p><strong>Accurate and scalable exchange-correlation with deep learning</strong><br>
Giulia Luise, Chin-Wei Huang, Thijs Vogels, Derk P. Kooi, Sebastian Ehlert, Stephanie Lanius, Klaas J. H. Giesbertz, Amir Karton, Deniz Gunceler, Megan Stanley, Wessel P. Bruinsma, Lin Huang, Xinran Wei, José Garrido Torres, Abylay Katbashev, Rodrigo Chavez Zavaleta, Bálint Máté, <strong>Sékou-Oumar Kaba</strong>, Roberto Sordillo, Yingrong Chen, David B. Williams-Young, Christopher M. Bishop, Jan Hermann, Rianne van den Berg, Paola Gori-Giorgi <br>
<em>Preprint</em> <br>
arXiv:<a href="https://arxiv.org/abs/2506.14665">2506.14665</a></p>
<p><strong>Improving equivariant networks with probabilistic symmetry breaking</strong><br>
Hannah Lawrence*, Vasco Portilheiro*, Yan Zhang, <strong>Sékou-Oumar Kaba</strong> <br>
<em>International Conference on Learning Representations (ICLR), 2025</em>
arXiv:<a href="https://arxiv.org/abs/2503.21985">2503.21985</a></p>
<p><strong>SymmCD: Symmetry-preserving crystal generation with diffusion models</strong><br>
Daniel Levy, Siba Smarak Panigrahi, <strong>Sékou-Oumar Kaba</strong>, Qiang Zhu, Mikhail Galkin, Santiago Miret, Siamak Ravanbakhsh <br>
<em>International Conference on Learning Representations (ICLR), 2025</em>
arXiv:<a href="https://arxiv.org/abs/2502.03638">2502.03638</a></p>
<p><strong>(Oral) Symmetry breaking and equivariant neural networks</strong><br>
<strong>Sékou-Oumar Kaba</strong>, Siamak Ravanbakhsh<br>
<em>NeurIPS 2023 Workshop on Symmetry and Geometry in Neural Representations, 2023</em> <br>
arXiv:<a href="https://arxiv.org/abs/2312.09016">2312.09016</a></p>
<p><strong>Equivariant adaptation of large pre-trained models</strong><br>
Arnab Kumar Mondal*, Siba Smarak Panigrahi*, <strong>Sékou-Oumar Kaba</strong>, Sai Rajeswar, Siamak Ravanbakhsh<br>
<em>Advances in Neural Information Processing Systems (NeurIPS), 2023</em><br>
arXiv:<a href="https://arxiv.org/abs/2310.01647">2310.01647</a></p>
<p><strong>Equivariance with learned canonicalization functions</strong><br>
<strong>Sékou-Oumar Kaba</strong>*, Arnab Kumar Mondal*, Yan Zhang, Yoshua Bengio, Siamak Ravanbakhsh  <br>
<em>International Conference on Machine Learning (ICML), 2023</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.06489">2211.06489</a></p>
<p><strong>Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural Networks</strong><br>
Daniel Levy*, <strong>Sékou-Oumar Kaba</strong>*, Carmelo Gonzales, Santiago Miret, Siamak Ravanbakhsh<br>
<em>ICML 2023 Workshop on Machine Learning for Astrophysics, 2023</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.06489">2211.06489</a></p>
<p><strong>Prediction of large magnetic moment materials with graph neural networks and random forests</strong><br>
<strong>Sékou-Oumar Kaba</strong>, Benjamin Groleau-Paré, Marc-Antoine Gauthier, A-MS Tremblay, Simon Verret, Chloé Gauvin-Ndiaye<br>
<em>Physical Review Materials</em><br>
arXiv:<a href="https://arxiv.org/abs/2111.14712">2111.14712</a></p>
<p><strong>Equivariant networks for crystal structures</strong><br>
<strong>Sékou-Oumar Kaba</strong>, Siamak Ravanbakhsh<br>
<em>Advances in Neural Information Processing Systems (NeurIPS), 2022</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.15420">2211.15420</a></p>
<p><strong>(Oral) Equivariance with learned canonicalization functions</strong><br>
<strong>Sékou-Oumar Kaba</strong>*, Arnab Kumar Mondal*, Yan Zhang, Yoshua Bengio, Siamak Ravanbakhsh  <br>
<em>NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations, 2022</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.06489">2211.06489</a></p>
<p><strong>Gradient starvation: A learning proclivity in neural networks</strong><br>
Mohammad Pezeshki, <strong>Sékou-Oumar Kaba</strong>, Yoshua Bengio, Aaron Courville, Doina Precup, Guillaume Lajoie  <br>
<em>Advances in Neural Information Processing Systems (NeurIPS), 2021</em><br>
arXiv:<a href="https://arxiv.org/abs/2011.09468">2011.09468</a></p>
<p><strong>Group-theoretical classification of superconducting states of strontium ruthenate</strong><br>
<strong>Sékou-Oumar Kaba</strong>, David Sénéchal<br>
<em>Physical Review B, 100 (21), 214507, 2019</em>  <br>
arXiv:<a href="https://arxiv.org/abs/1905.10467">1905.10467</a></p>
</article>
        </main><footer id="footer">
    Last updated: October 2024. Copyright © 2024 Sékou-Oumar Kaba
</footer>
</body>
</html>
