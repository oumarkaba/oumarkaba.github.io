<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Oumar&#39;s Website">
    
    <link rel="shortcut icon" href="http://oumarkaba.github.io/favicon.ico">
    
    <link rel="stylesheet" href="/css/style.min.css">

    <title>Publications</title>
</head>
<body><header id="banner">
    <h2><a href="http://oumarkaba.github.io">Sékou-Oumar Kaba</a></h2>
    <nav>
        <ul>
            <li>
                <a href="/resume/" title="resume">resume</a>
            </li><li>
                <a href="/publications/" title="publications">publications</a>
            </li>
        </ul>
    </nav>
</header>
<main id="content">
<article>
    <header id="post-header">
        <h1>Publications</h1>
        <div></div>
    </header><!-- ### Papers -->
<p><strong>(Oral) Symmetry breaking and equivariant neural networks</strong><br>
<strong>Sékou-Oumar Kaba</strong>, Siamak Ravanbakhsh<br>
<em>NeurIPS 2023 Workshop on Symmetry and Geometry in Neural Representations, 2023</em></p>
<p><strong>Equivariant adaptation of large pre-trained models</strong><br>
Arnab Kumar Mondal*, Siba Smarak Panigrahi*, <strong>Sékou-Oumar Kaba</strong>, Sai Rajeswar, Siamak Ravanbakhsh<br>
<em>Advances in Neural Information Processing Systems (NeurIPS), 2023</em><br>
arXiv:<a href="https://arxiv.org/abs/2310.01647">2310.01647</a></p>
<p><strong>Equivariance with learned canonicalization functions</strong><br>
<strong>Sékou-Oumar Kaba</strong>*, Arnab Kumar Mondal*, Yan Zhang, Yoshua Bengio, Siamak Ravanbakhsh  <br>
<em>International Conference on Machine Learning (ICML), 2023</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.06489">2211.06489</a></p>
<p><strong>Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural Networks</strong><br>
Daniel Levy*, <strong>Sékou-Oumar Kaba</strong>*, Carmelo Gonzales, Santiago Miret, Siamak Ravanbakhsh<br>
<em>International Conference on Machine Learning (ICML), 2023</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.06489">2211.06489</a></p>
<p><strong>Prediction of large magnetic moment materials with graph neural networks and random forests</strong><br>
<strong>Sékou-Oumar Kaba</strong>, Benjamin Groleau-Paré, Marc-Antoine Gauthier, A-MS Tremblay, Simon Verret, Chloé Gauvin-Ndiaye<br>
<em>Physical Review Materials</em><br>
arXiv:<a href="https://arxiv.org/abs/2111.14712">2111.14712</a></p>
<p><strong>Equivariant networks for crystal structures</strong><br>
<strong>Sékou-Oumar Kaba</strong>, Siamak Ravanbakhsh<br>
<em>Advances in Neural Information Processing Systems (NeurIPS), 2022</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.15420">2211.15420</a></p>
<p><strong>(Spotlight) Equivariance with learned canonicalization functions</strong><br>
<strong>Sékou-Oumar Kaba</strong>*, Arnab Kumar Mondal*, Yan Zhang, Yoshua Bengio, Siamak Ravanbakhsh  <br>
<em>NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations, 2022</em><br>
arXiv:<a href="https://arxiv.org/abs/2211.06489">2211.06489</a></p>
<p><strong>Gradient starvation: A learning proclivity in neural networks</strong><br>
Mohammad Pezeshki, <strong>Sékou-Oumar Kaba</strong>, Yoshua Bengio, Aaron Courville, Doina Precup, Guillaume Lajoie  <br>
<em>Advances in Neural Information Processing Systems (NeurIPS), 2021</em><br>
arXiv:<a href="https://arxiv.org/abs/2011.09468">2011.09468</a></p>
<p><strong>Group-theoretical classification of superconducting states of strontium ruthenate</strong><br>
<strong>Sékou-Oumar Kaba</strong>, David Sénéchal<br>
<em>Physical Review B, 100 (21), 214507, 2019</em>  <br>
arXiv:<a href="https://arxiv.org/abs/1905.10467">1905.10467</a></p>
</article>
        </main><footer id="footer">
    Copyright © 2023 Sékou-Oumar Kaba
</footer>
</body>
</html>
